#####################################################################
# Example : How to manage an app via ENV-variables and the KST tool?
#####################################################################

#
# We define the credentials for cluster access as environment variables
#
source setenv.sh

cd ..

mvn clean compile install

#
# Select a system definition folder which holds the metadata used and generated by KST
#
export sdf=example10

#
# Select a target environment (inside a system definition folder)
#
export KST_ENVIRONMENT_FILENAME=./src/main/cluster-state-tools-data/$sdf/environments.yaml

#
# Select a target cluster from above environment descriptor
#
export KST_TARGET_CLUSTER_NAME=cluster_2

#
# Select a target domain, from the domain-definition-folder from above environment descriptor
#

export KST_TARGET_DOMAIN_NAME=random-number-analysis
#
# Export the PROPERTIES files for KAFKA clients
#
##   TODO: Export log4j properties file according to the environment in the cpf folder.
##   TODO: Export KSQLDB properties file according to the environment in the cpf folder.
#
java -cp target/ks-inspector-1.0-SNAPSHOT.jar io.confluent.cp.governanceprocess.PropertyFileExporter ./src/main/cluster-state-tools-data/$sdf/domains
#
# use exported properties for local KST execution against the selected cluster
#
echo "-----------------------------------------------------------------------------------------------------------------"
echo "> grab a copy of the exported client configuration:"
echo "> cp ./src/main/cluster-state-tools-data/example10/cpf/cp-client-props-$KST_TARGET_CLUSTER_NAME.properties kst.properties"
cp ./src/main/cluster-state-tools-data/example10/cpf/cp-client-props-$KST_TARGET_CLUSTER_NAME.properties kst.properties
echo "------------------------------------------------------------------------------------------------------------------"
echo

#
# Prepare the target environment
#
java -jar ./kafka-clusterstate-tools/build/libs/kafka-clusterstate-tools-1.0.1-SNAPSHOT.jar apply ./src/main/cluster-state-tools-data/example10/domains -c ./src/main/cluster-state-tools-data/$sdf/cpf/cp-client-props-$KST_TARGET_CLUSTER_NAME.properties
#java -jar ./kafka-clusterstate-tools/build/libs/kafka-clusterstate-tools-1.0.1-SNAPSHOT.jar apply .e10/domains -c ./kst.properties
#
# # alternatively, with our KSTWrapper (WIP)
#
#java -cp target/ks-inspector-1.0-SNAPSHOT.jar io.confluent.cp.util.KSTWrapper ./src/main/cluster-state-tools-data/$sdf/environments.yaml

#
# Start the RNG application
#
# #  TODO: Configure log4j properties file path manually according to the environment and selected cluster.
#          This allows logging into the Kafka topic.
#
java -cp target/ks-inspector-1.0-SNAPSHOT.jar io.confluent.cp.apps.RandomSeriesGeneratorApp

#
# Start KSQL DB application
#
docker run -d \
  --network=host \
  -p 127.0.0.1:8188:8188 \
  -e KSQL_BOOTSTRAP_SERVERS=pkc-l7q2j.europe-north1.gcp.confluent.cloud:9092 \
  -e KSQL_LISTENERS=http://0.0.0.0:8188/ \
  -e KSQL_KSQL_SERVICE_ID=default_MK_ \
  -e KSQL_KSQL_SINK_REPLICAS=3 \
  -e KSQL_KSQL_STREAMS_REPLICATION_FACTOR=3 \
  -e KSQL_KSQL_INTERNAL_TOPIC_REPLICAS=3 \
  -e KSQL_SECURITY_PROTOCOL=SASL_SSL \
  -e KSQL_SASL_MECHANISM=PLAIN \
  -e KSQL_SASL_JAAS_CONFIG="org.apache.kafka.common.security.plain.PlainLoginModule required username=\"AG2X57TIVLOSA2UF\" password=\"128ALrmHYSzfyrmffHIj9HwgtEBeyjHZ2qQidBXnd/tPbpLRZL1mojIH97G05Har\";" \
  -e KSQL_SCHEMA_REGISTRY_BASIC_AUTH_CREDENTIALS_SOURCE=USER_INFO \
  -e KSQL_SCHEMA_REGISTRY_URL=https://psrc-4v1qj.eu-central-1.aws.confluent.cloud \
  confluentinc/ksqldb-server:latest

#
# Start KSQL DB CLI
#
docker run -it --network=host confluentinc/ksqldb-cli ksql http://127.0.0.1:8188
